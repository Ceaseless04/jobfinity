{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55b5a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../data/sample_resumes/Resume/resumeDataSet2_transformed_filtered.csv\")\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "data = df.copy().iloc[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a5b75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Clear existing entity ruler if any\n",
    "if \"entity_ruler\" in nlp.pipe_names:\n",
    "    nlp.remove_pipe(\"entity_ruler\")\n",
    "\n",
    "# Add entity ruler\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
    "\n",
    "# Define skill categories\n",
    "SweSkills = [\"Python\", \"Java\", \"JavaScript\", \"C++\", \"React\", \"Angular\", \"Node.js\", \"Git\", \"CI/CD\"]\n",
    "DsSkills = [\"Python\", \"R\", \"SQL\", \"Machine Learning\", \"Data Analysis\", \"Statistics\", \"TensorFlow\", \"PyTorch\"]\n",
    "DoSkills = [\"Linux\", \"Docker\", \"Kubernetes\", \"AWS\", \"Azure\", \"CI/CD\", \"Jenkins\", \"Terraform\", \"Ansible\"]\n",
    "\n",
    "# Create patterns\n",
    "patterns = []\n",
    "for skill in SweSkills:\n",
    "    patterns.append({\"label\": \"SWE\", \"pattern\": skill})\n",
    "for skill in DsSkills:\n",
    "    patterns.append({\"label\": \"DATASCIENCE\", \"pattern\": skill})\n",
    "for skill in DoSkills:\n",
    "    patterns.append({\"label\": \"DEVOPS\", \"pattern\": skill})\n",
    "\n",
    "# Add patterns to ruler\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c6ba043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples\n",
    "examples = []\n",
    "for text in data['Resume_str']:\n",
    "    # Create docs\n",
    "    doc = nlp.make_doc(text)\n",
    "    processed_doc = nlp(text)\n",
    "    \n",
    "    # Get entities\n",
    "    entities = []\n",
    "    for ent in processed_doc.ents:\n",
    "        entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "    \n",
    "    # Create reference doc\n",
    "    ref_doc = nlp.make_doc(text)\n",
    "    spans = []\n",
    "    for start, end, label in entities:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            spans.append(span)\n",
    "    ref_doc.ents = spans\n",
    "    \n",
    "    # Create example\n",
    "    example = Example(doc, ref_doc)\n",
    "    examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a79d742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 15493.518325675966}\n",
      "Iteration 1, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 4866.753208094015}\n",
      "Iteration 2, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 2628.4833126113463}\n",
      "Iteration 3, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 1766.408451013135}\n",
      "Iteration 4, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 1167.9157375047607}\n",
      "Iteration 5, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 912.3970398268485}\n",
      "Iteration 6, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 788.7775304283356}\n",
      "Iteration 7, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 683.5223332765775}\n",
      "Iteration 8, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 621.0065984775883}\n",
      "Iteration 9, Losses: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 706.1355272609607}\n"
     ]
    }
   ],
   "source": [
    "# Define get_examples function\n",
    "def get_examples():\n",
    "    return examples\n",
    "\n",
    "# Initialize the model\n",
    "optimizer = nlp.initialize(get_examples=get_examples)\n",
    "\n",
    "# Training loop\n",
    "for i in range(10):\n",
    "    random.shuffle(examples)\n",
    "    losses = {}\n",
    "    for example in examples:\n",
    "        nlp.update([example], sgd=optimizer, losses=losses)\n",
    "    print(f\"Iteration {i}, Losses: {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "616279bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the model on sample text:\n",
      "\n",
      "Example 1:\n",
      "Text preview: Skills Strong CS fundamentals and problem solving Ethereum, Smart Contracts, Solidity skills Golang, Node, Angular, React Culturally fit for startup environment MongoDB, PostGresql, MySql Enthusiastic ...\n",
      "\n",
      "  - 'Skills' (PERSON) [0:6]\n",
      "  - 'Ethereum' (ORG) [50:58]\n",
      "  - 'Golang' (GPE) [93:99]\n",
      "  - 'Node' (PERSON) [101:105]\n",
      "  - 'Angular' (SWE) [107:114]\n",
      "  - 'React' (SWE) [116:121]\n",
      "  - 'PostGresql' (ORG) [170:180]\n",
      "  - 'MySql' (PERSON) [182:187]\n",
      "  - 'AWS' (DEVOPS) [227:230]\n",
      "  - 'Docker' (DEVOPS) [232:238]\n",
      "  - 'Microservices' (ORDINAL) [240:253]\n",
      "  - 'January' (SWE) [305:312]\n",
      "  - 'Engineering' (ORDINAL) [334:345]\n",
      "  - 'Blockchain' (ORDINAL) [524:534]\n",
      "  - 'Skill' (ORDINAL) [566:571]\n",
      "  - '16' (SWE) [603:605]\n",
      "  - 'CONTRACTS-' (ORG) [614:624]\n",
      "  - 'Exprience' (GPE) [655:664]\n",
      "  - '9' (SWE) [667:668]\n",
      "  - 'Exprience' (GPE) [721:730]\n",
      "  - 'Xinfin' (GPE) [803:809]\n",
      "  - 'Hybrid' (ORDINAL) [834:840]\n",
      "  - 'Tradefinex' (PERSON) [964:974]\n",
      "  - 'Land' (TIME) [1002:1006]\n",
      "  - 'ERC' (ORG) [1111:1114]\n",
      "  - '20' (CARDINAL) [1115:1117]\n",
      "  - 'XINFIN' (DATASCIENCE) [1132:1138]\n",
      "  - 'Solidity' (GPE) [1233:1241]\n",
      "  - 'DAPPs' (ORG) [1260:1265]\n",
      "  - 'OroWealth' (ORG) [1311:1320]\n",
      "  - 'zero' (CARDINAL) [1326:1330]\n",
      "  - 'KYC' (PERSON) [1575:1578]\n",
      "  - 'MF' (ORDINAL) [1583:1585]\n",
      "  - 'Node.js' (SWE) [1609:1616]\n",
      "  - 'Angular.js' (GPE) [1618:1628]\n",
      "  - 'Telangana' (GPE) [1695:1704]\n",
      "  - 'U.A.E' (GPE) [1760:1765]\n",
      "  - '22' (CARDINAL) [1776:1778]\n",
      "  - 'K' (ORG) [1778:1779]\n",
      "  - 'Vendor' (ORG) [1868:1874]\n",
      "  - 'CakePHP' (PERSON) [2028:2035]\n",
      "  - 'PHP' (PERSON) [2037:2040]\n",
      "  - 'JQuery' (ORG) [2053:2059]\n",
      "  - 'Mumbai' (GPE) [2108:2114]\n",
      "  - 'API' (ORG) [2299:2302]\n",
      "  - 'Ecommerce' (ORDINAL) [2337:2346]\n",
      "  - 'JQuery' (ORG) [2359:2365]\n",
      "  - 'description' (PERSON) [2425:2436]\n",
      "  - 'Dallas' (GPE) [2512:2518]\n",
      "  - 'USA' (GPE) [2520:2523]\n",
      "  - 'India' (GPE) [2540:2545]\n",
      "\n",
      "Example 2:\n",
      "Text preview: Skills VISA B1-VISA (USA) Onsite Visits to Sweden & US (Seattle) Education Details \n",
      "January 2013 Post Graduate Diploma Information Technology Pune, Maharashtra Symbiosis Institute\n",
      "January 2007 Bache ...\n",
      "\n",
      "  - 'Sweden' (GPE) [43:49]\n",
      "  - 'Seattle' (GPE) [56:63]\n",
      "  - 'January' (SWE) [85:92]\n",
      "  - 'January' (SWE) [182:189]\n",
      "  - 'Telecommunications' (ORDINAL) [235:253]\n",
      "  - 'DevOps' (ORG) [317:323]\n",
      "  - 'DevOps' (ORG) [357:363]\n",
      "  - '48' (SWE) [420:422]\n",
      "  - '96' (ORDINAL) [460:462]\n",
      "  - 'Python-' (DATASCIENCE) [471:478]\n",
      "  - '6' (LAW) [491:492]\n",
      "  - 'Automation-' (DATASCIENCE) [501:512]\n",
      "  - 'Exprience' (GPE) [513:522]\n",
      "  - '72' (ORDINAL) [525:527]\n",
      "  - 'Exprience' (GPE) [600:609]\n",
      "  - 'DevOps' (DATASCIENCE) [733:739]\n",
      "  - 'AWS' (DEVOPS) [761:764]\n",
      "  - 'Azure' (DEVOPS) [772:777]\n",
      "  - 'AWS' (DEVOPS) [796:799]\n",
      "  - 'RDS' (ORG) [805:808]\n",
      "  - 'CloudFormation' (SWE) [810:824]\n",
      "  - 'Lambda' (NORP) [835:841]\n",
      "  - 'Dynamo' (PERSON) [843:849]\n",
      "  - 'Elastic' (NORP) [882:889]\n",
      "  - 'Appdynamics' (ORG) [902:913]\n",
      "  - 'Ops' (ORG) [998:1001]\n",
      "  - 'India' (GPE) [1012:1017]\n",
      "  - '15' (CARDINAL) [1067:1069]\n",
      "  - '4' (CARDINAL) [1096:1097]\n",
      "  - 'Projects' (ORG) [1108:1116]\n",
      "  - '1' (CARDINAL) [1241:1242]\n",
      "  - '2' (CARDINAL) [1301:1302]\n",
      "  - 'India' (GPE) [1312:1317]\n",
      "  - '3' (CARDINAL) [1376:1377]\n",
      "  - '4' (CARDINAL) [1428:1429]\n",
      "  - '4' (CARDINAL) [1461:1462]\n",
      "  - '5' (CARDINAL) [1474:1475]\n",
      "  - 'AWS' (DEVOPS) [1506:1509]\n",
      "  - 'Team' (ORG) [1530:1534]\n",
      "  - 'Shell' (ORG) [1539:1544]\n",
      "  - 'AWS' (DEVOPS) [1610:1613]\n",
      "  - 'EIP' (ORG) [1690:1693]\n",
      "  - 'Lambda' (NORP) [1724:1730]\n",
      "  - 'Linux' (DEVOPS) [1885:1890]\n",
      "  - 'Linux' (DEVOPS) [1897:1902]\n",
      "  - 'Redhat' (PERSON) [1935:1941]\n",
      "  - '1' (CARDINAL) [2043:2044]\n",
      "  - '2' (CARDINAL) [2115:2116]\n",
      "  - 'Linux' (DEVOPS) [2127:2132]\n",
      "  - '3' (CARDINAL) [2158:2159]\n",
      "  - 'Satellite' (ORG) [2192:2201]\n",
      "  - '4' (CARDINAL) [2211:2212]\n",
      "  - 'DB' (NORP) [2255:2257]\n",
      "  - 'Tsys' (TIME) [2327:2331]\n",
      "  - 'Linux' (DEVOPS) [2410:2415]\n",
      "  - 'RHDS' (ORG) [2538:2542]\n",
      "  - 'Cvs' (PERSON) [2544:2547]\n",
      "  - 'VDI' (ORG) [2629:2632]\n",
      "  - '1' (CARDINAL) [2759:2760]\n",
      "  - '2' (CARDINAL) [2890:2891]\n",
      "  - '3' (CARDINAL) [2945:2946]\n",
      "  - 'P8' (CARDINAL) [3165:3167]\n",
      "  - 'Linux' (DEVOPS) [3177:3182]\n",
      "  - 'IBM' (ORG) [3189:3192]\n",
      "  - 'HTML' (ORG) [3227:3231]\n",
      "  - 'Genworth' (DATASCIENCE) [3259:3267]\n",
      "  - '2' (CARDINAL) [3289:3290]\n",
      "  - '2' (SWE) [3295:3296]\n",
      "  - 'Role' (PERSON) [3306:3310]\n",
      "  - 'Genworth' (TIME) [3454:3462]\n",
      "  - 'Providers' (ORG) [3577:3586]\n",
      "  - 'Oracle' (PRODUCT) [3617:3623]\n",
      "  - 'L1' (NORP) [3790:3792]\n",
      "  - '10' (CARDINAL) [3914:3916]\n",
      "  - 'Linux' (DEVOPS) [3917:3922]\n",
      "  - 'SQL' (DATASCIENCE) [4095:4098]\n",
      "  - 'SQL' (DATASCIENCE) [4123:4126]\n",
      "  - 'eProcess' (ORG) [4502:4510]\n",
      "  - 'Trexo' (PERSON) [4512:4517]\n",
      "  - 'Shell' (ORG) [4670:4675]\n",
      "  - 'five' (SWE) [4754:4758]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rai/Developer/code/jobfinity/venv/lib/python3.10/site-packages/spacy/pipeline/attributeruler.py:149: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  matches = self.matcher(doc, allow_missing=True, as_spans=False)\n",
      "/Users/rai/Developer/code/jobfinity/venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/rai/Developer/code/jobfinity/venv/lib/python3.10/site-packages/spacy/pipeline/entityruler.py:405: UserWarning: [W036] The component 'entity_ruler' does not have any patterns defined.\n",
      "  warnings.warn(Warnings.W036.format(name=self.name))\n",
      "/Users/rai/Developer/code/jobfinity/venv/lib/python3.10/site-packages/spacy/pipeline/attributeruler.py:149: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  matches = self.matcher(doc, allow_missing=True, as_spans=False)\n",
      "/Users/rai/Developer/code/jobfinity/venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/rai/Developer/code/jobfinity/venv/lib/python3.10/site-packages/spacy/pipeline/entityruler.py:405: UserWarning: [W036] The component 'entity_ruler' does not have any patterns defined.\n",
      "  warnings.warn(Warnings.W036.format(name=self.name))\n"
     ]
    }
   ],
   "source": [
    "# Test on a few examples\n",
    "print(\"\\nTesting the model on sample text:\")\n",
    "for i, text in enumerate(data['Resume_str'][:2]):\n",
    "    doc = nlp(text)\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Text preview:\", text[:200], \"...\\n\")\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        print(f\"  - '{ent.text}' ({ent.label_}) [{ent.start_char}:{ent.end_char}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7ba45e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/spacy_skill_ner\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "output_dir = \"../models/spacy_skill_ner\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeeb7e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Skills:\n",
      "SWE: Python, Java, JavaScript\n",
      "DATASCIENCE: SQL\n",
      "DEVOPS: Docker, AWS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rai/Developer/code/jobfinity/venv/lib/python3.10/site-packages/spacy/pipeline/attributeruler.py:149: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  matches = self.matcher(doc, allow_missing=True, as_spans=False)\n",
      "/Users/rai/Developer/code/jobfinity/venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/rai/Developer/code/jobfinity/venv/lib/python3.10/site-packages/spacy/pipeline/entityruler.py:405: UserWarning: [W036] The component 'entity_ruler' does not have any patterns defined.\n",
      "  warnings.warn(Warnings.W036.format(name=self.name))\n"
     ]
    }
   ],
   "source": [
    "# Example of how to load and use the saved model\n",
    "def extract_skills(resume_text):\n",
    "    # Load the saved model\n",
    "    loaded_nlp = spacy.load(\"../models/spacy_skill_ner\")\n",
    "    \n",
    "    doc = loaded_nlp(resume_text)\n",
    "    skills = {\n",
    "        \"SWE\": [],\n",
    "        \"DATASCIENCE\": [],\n",
    "        \"DEVOPS\": []\n",
    "    }\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in skills:\n",
    "            if ent.text not in skills[ent.label_]:\n",
    "                skills[ent.label_].append(ent.text)\n",
    "    \n",
    "    return skills\n",
    "\n",
    "# Test the inference\n",
    "sample_text = \"\"\"\n",
    "TECHNICAL SKILLS\n",
    "Programming Languages: Python, Java, JavaScript\n",
    "Data Science: SQL, Machine Learning, TensorFlow\n",
    "DevOps: Docker, AWS, Kubernetes\n",
    "\"\"\"\n",
    "\n",
    "extracted_skills = extract_skills(sample_text)\n",
    "print(\"\\nExtracted Skills:\")\n",
    "for category, skills in extracted_skills.items():\n",
    "    print(f\"{category}: {', '.join(skills)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
